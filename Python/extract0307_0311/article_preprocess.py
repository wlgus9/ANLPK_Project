# -*- coding: utf-8 -*-
"""ANLKP전처리모듈.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AyV2-p45AnOUy4EXTwwvXwGRiG2BlHFU
"""

import pandas as pd
import re


######## 전처리 데이터 준비 #######

def create_preprocessed_data(raw_data_file, ver, path = "extract0228_0304/Article_preprocessed"):
    """
     전처리 데이터를 생성하여 지정한 경로에 저장하는 함수
     raw_data_file : 원본데이터 파일, path : 저장 위치
    """
    # 데이터 로드
    df = set_data(raw_data_file)

    # 카테고리 목록
    cate_list = category_list(df)

    # 전처리 후 전처리 파일을 카테고리 별로 저장 (※기사별 고유명사 컬럼이 추가됌)
    train_preprocessed = preprocess_article(df)

    # 전처리 된 데이터 카테고리 별로 분리하여 저장
    split_data_cate(train_preprocessed,ver,path)

    return cate_list







###### 기사 전처리 함수
def preprocess_article(df):
    """
     기사 데이터 본문 전처리 및 고유명사 리스트 컬럼 추가
     df : 데이터프레임,
     return : 본문전처리 + 고유명사 컬럼 데이터프레임

    """

    # 영어 본문 제거
    df = drop_article_eng(df)

    # 언론사 리스트 추출
    sources = source_list(df)

    # 고유 명사 추출 -> 고유명사 컬럼에 추가
    df['proper_nouns'] = df['article']
    df['proper_nouns'] = df['proper_nouns'].apply(lambda x: extract_proper_nouns(x))

    # 기사 전처리 함수
    df = preprocessing_text(df, sources)

    df.dropna(inplace=True)
    df.reset_index(drop=True, inplace=True)

    return df


# 전처리할 데이터 불러오기 및 결측치 처리
def set_data(file):
    train_data = pd.read_csv(file)
    train_data.dropna(axis=0, inplace=True)
    train_data.reset_index(drop=True, inplace=True)

    return train_data


# 카테고리 리스트
def category_list(df):
    df_new = df.drop_duplicates(subset="category")
    cate_list = sorted(df_new['category'].astype(str))
    return cate_list


# (전체 기사 전처리 후) 기사 카테고리 별로 분리
def split_data_cate(df, version, path):
    """
    데이터 카테고리별로 분리 및 저장
    df : pandas.Dataframe , version : int
    """
    cate_list = category_list(df)
    for category in cate_list:
        df_cate = df[df['category'] == category]
        save_data(df_cate, path + '/preprocessed_' + category + '_V' + str(version) + '.csv')
        print(path+'에 '+category+'_V' + str(version)+' 전처리 파일 저장 완료')


# 언론사 리스트 추출
def source_list(df):
    df_new = df.drop_duplicates(subset="source")
    source = sorted(df_new['source'].astype(str))
    new_source = []
    for word in source:
        new_word = re.sub('[^A-Za-z0-9가-힣”’]', '', word)
        if new_word != '':
            new_source.append(new_word)

    new_source = list(set(new_source))
    return new_source


# 고유명사 추출
def extract_proper_nouns(docs):
  """
  ''안의 고유명사 리스트 추출(+ 각 문서내 중복 고유명사 제거)

  :param df_article: ※※전처리 전※※ 데이터 프레임 내 기사
  :return: 추출한 고유명사
  """

  proper_noun = re.findall('‘[A-Za-z0-9가-힣 ]+’', str(docs))

  proper_noun = set(proper_noun)
  proper_noun = list(proper_noun)
  proper_nouns = [word.replace(' ', '').replace('‘', '').replace('’', '') for word in proper_noun]
  proper_nouns_txt = " ".join(proper_nouns)

  return proper_nouns_txt


# 영어본문 제거
def drop_article_eng(df):
    new_docs = []

    print(df.isnull().sum())
    for docs in df['article']:
        # 한글을 못찾았을 경우
        if len(re.findall('[가-힣]', str(docs))) == 0:
            new_doc = None
        elif (len(re.findall('[가-힣]',str(docs)))/len(str(docs))*100)<=10:
            new_doc = None
        else:
            new_doc = docs

        new_docs.append(new_doc)

    df['article'] = pd.DataFrame(new_docs)

    print(df.isnull().sum())

    df.dropna(axis=0, inplace=True)
    df.reset_index(drop=True, inplace=True)

    return df


# 정규표현식으로 이메일, 언론사, 기자 이름, 특수문자 제거, 한음절 글자 제거, 숫자만 있는 글자 제거
# 연속된 띄어쓰기 -> 단일 띄어씌기로 통일

def preprocessing_text(df, l_source):
    new_docs = []
    idx = 0
    cnt = 1
    for docs in df['article']:

        # new_doc = docs.replace('\\n', '')
        # 이메일 제거
        new_doc = re.sub('[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+', '', str(docs))
        print(cnt)
        cnt += 1
        # 기자 이름 제거 1번째 시도 (name 컬럼이용)
        # 양식 그대로 제거
        # new_doc = re.sub(df['name'][idx], '', new_doc)
        # print(cnt)
        # cnt+=1
        # 2인 이상일때
        l = list(set(re.split(r'[^A-Za-z0-9가-힣]', df['name'][idx])))
        for word in l:
            new_doc = re.sub(word, '', new_doc)

        idx += 1
        print(cnt)
        cnt += 1

        # 기자 이름 제거
        new_doc = re.sub('[가-힣 ]+ ?기자', '', new_doc)
        new_doc = re.sub('[가-힣 ]+ ?특파원', '', new_doc)
        print(cnt)
        cnt += 1
        # (지역=언론사) 양식 제거
        new_doc = re.sub('[A-Za-z가-힣 ]+=[가-힣0-9 ]+', '', new_doc)
        print(cnt)
        cnt += 1

        # r_num = new_doc.rfind(',')
        # if new_doc[r_num:].rfind('기자'):
        #     new_doc = new_doc = str(new_doc[0:r_num+1])
        # if new_doc[r_num:].rfind('특파원'):
        #     new_doc = new_doc = str(new_doc[0:r_num+1])
        # if new_doc.find(' = '):
        #     l_num = new_doc.find(' = ')
        #     new_doc = str(new_doc[l_num+1:])

        # 홑 따옴표 안에 문자열 제거
        new_doc = re.sub('’.+’', ' ', new_doc)

        # 특수문자 제거
        new_doc = re.sub('[^A-Za-z0-9가-힣”’-]', ' ', new_doc)
        new_doc = new_doc.replace('”', '')
        new_doc = new_doc.replace('’', '')
        new_doc = new_doc.strip()
        new_doc = ' '.join(new_doc.split())
        print(cnt)
        cnt += 1

        # 언론사 제거
        for word in l_source:
            new_doc = re.sub(word, ' ', new_doc)
        new_doc = new_doc.strip()
        new_doc = ' '.join(new_doc.split())
        print(cnt)
        cnt += 1

        # 한음절 글자 제거
        new_doc = re.sub(' . ', ' ', new_doc)
        new_doc = re.sub(' . ', ' ', new_doc)
        new_doc = re.sub(' . ', ' ', new_doc)
        new_doc = new_doc.strip()
        new_doc = ' '.join(new_doc.split())
        print(cnt)
        cnt += 1

        # 숫자만 있는 글자 제거
        new_doc = re.sub(' [-]?[0-9]+ ', ' ', new_doc)
        new_doc = new_doc.strip()
        new_doc = ' '.join(new_doc.split())
        print(cnt)
        cnt += 1

        # 숫자+글자(공백전까지) 제거(+,-)
        new_doc = re.sub(' [-]?[0-9]+[A-Za-z가-힣]+', ' ', new_doc)
        new_doc = re.sub(' [-]?[0-9]+[A-Za-z가-힣]+', ' ', new_doc)
        new_doc = re.sub(' [-]?[0-9]+[A-Za-z가-힣]+', ' ', new_doc)
        new_doc = new_doc.strip()
        new_doc = ' '.join(new_doc.split())
        print(cnt)
        cnt += 1

        # (-)+글자 제거
        new_doc = re.sub(' [-][A-Za-z가-힣]+ ', ' ', new_doc)
        new_doc = re.sub(' [-][A-Za-z가-힣]+ ', ' ', new_doc)
        new_doc = re.sub(' [-][A-Za-z가-힣]+ ', ' ', new_doc)

        new_doc = new_doc.strip()
        new_doc = ' '.join(new_doc.split())
        print(cnt)
        cnt += 1

        if new_doc == '' or new_doc == ' ':
            new_doc = None
        new_docs.append(new_doc)
    df['article'] = pd.DataFrame(new_docs)

    return df

# 전처리 된 데이터 저장

def save_data(df, name):
    df.to_csv(name, encoding='utf-8-sig', index=False)

